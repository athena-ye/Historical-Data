{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: illegal option -- 1\r\n",
      "usage: wc [-clmw] [file ...]\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import geopy.distance\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import scipy as sci\n",
    "import scipy.signal as sig\n",
    "import scipy.spatial as spa\n",
    "import scipy.stats as stat\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "ex = './Historical Data/%s.csv'\n",
    "path = ex % 'LCM'\n",
    "!wc -1 $psth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = importr('base')\n",
    "utils = importr('utils')\n",
    "stats = importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/Users/athenaye/Library/R/4.0/library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There is a binary version available but the source version is later:\n",
      "              binary source needs_compilation\n",
      "neonUtilities  2.1.3  2.1.4             FALSE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: installing the source package ‘neonUtilities’\n",
      "\n",
      "\n",
      "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/neonUtilities_2.1.4.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 186084 bytes (181 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 181 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/private/var/folders/17/5ynsg_xj1rq8f9r_5pc5tgv80000gn/T/Rtmpqzihlx/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.install_packages('neonUtilities', repos='https://cran.rstudio.com/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neonUtilities = importr('neonUtilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding available files\n",
      "  |======================================================================| 100%\n",
      "\n",
      "Downloading files totaling approximately 35.598907 MB\n",
      "Downloading 10 files\n",
      "  |======================================================================| 100%\n",
      "\n",
      "Unpacking zip files using 4 cores.\n",
      "  |                                                  | 0 % ~calculating   |+++++++++++++++++                                 | 33% ~00s           |++++++++++++++++++++++++++++++++++                | 67% ~00s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=00s  \n",
      "  |                                                  | 0 % ~calculating   |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=00s  \n",
      "File requirements do not meet the threshold for automatic parallelization. Running on single core.\n",
      "Stacking table RHbuoy_1min\n",
      "  |                                                  | 0 % ~calculating   |+++++                                             | 10% ~01s           |++++++++++                                        | 20% ~01s           |+++++++++++++++                                   | 30% ~00s           |++++++++++++++++++++                              | 40% ~00s           |+++++++++++++++++++++++++                         | 50% ~00s           |++++++++++++++++++++++++++++++                    | 60% ~00s           |+++++++++++++++++++++++++++++++++++               | 70% ~00s           |++++++++++++++++++++++++++++++++++++++++          | 80% ~00s           |+++++++++++++++++++++++++++++++++++++++++++++     | 90% ~00s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=01s  \n",
      "Stacking table RHbuoy_30min\n",
      "  |                                                  | 0 % ~calculating   |+++++                                             | 10% ~00s           |++++++++++                                        | 20% ~00s           |+++++++++++++++                                   | 30% ~00s           |++++++++++++++++++++                              | 40% ~00s           |+++++++++++++++++++++++++                         | 50% ~00s           |++++++++++++++++++++++++++++++                    | 60% ~00s           |+++++++++++++++++++++++++++++++++++               | 70% ~00s           |++++++++++++++++++++++++++++++++++++++++          | 80% ~00s           |+++++++++++++++++++++++++++++++++++++++++++++     | 90% ~00s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=00s  \n",
      "Merged the most recent publication of sensor position files for each site and saved to /stackedFiles\n",
      "Copied the most recent publication of variable definition file to /stackedFiles\n",
      "Finished: Stacked 2 data tables and 3 metadata tables!\n",
      "Stacking took 2.119375 secs\n"
     ]
    }
   ],
   "source": [
    "stacked = neonUtilities.loadByProduct(dpID= 'DP1.20271.001',\n",
    "                        site = 'TOOK',\n",
    "                        package='basic',\n",
    "                        check_size='FALSE',\n",
    "                        nCores = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>ListVector with 6 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            issueLog_20271\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.ListSexpVector object at 0x7ff388b32200> [RTYPES.VECSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            readme_20271\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.ListSexpVector object at 0x7ff388b32340> [RTYPES.VECSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            RHbuoy_1min\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.ListSexpVector object at 0x7ff388b32380> [RTYPES.VECSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            RHbuoy_30min\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.ListSexpVector object at 0x7ff388b322c0> [RTYPES.VECSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            sensor_positions_20271\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.ListSexpVector object at 0x7ff388b32480> [RTYPES.VECSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            variables_20271\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.ListSexpVector object at 0x7ff388b32500> [RTYPES.VECSXP]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x7ff39d2f3b00> [RTYPES.VECSXP]\n",
       "R classes: ('list',)\n",
       "[ListS..., ListS..., ListS..., ListS..., ListS..., ListS...]\n",
       "  issueLog_20271: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x7ff388b349c0> [RTYPES.VECSXP]\n",
       "  readme_20271: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x7ff388b34fc0> [RTYPES.VECSXP]\n",
       "  RHbuoy_1min: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x7ff388b320c0> [RTYPES.VECSXP]\n",
       "  RHbuoy_30min: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x7ff388b32080> [RTYPES.VECSXP]\n",
       "  sensor_positions_20271: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x7ff388b32280> [RTYPES.VECSXP]\n",
       "  variables_20271: <class 'rpy2.rinterface.ListSexpVector'>\n",
       "  <rpy2.rinterface.ListSexpVector object at 0x7ff388b32300> [RTYPES.VECSXP]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "                datainpd = ro.conversion.rpy2py(stacked[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['table', 'fieldName', 'description', 'dataType', 'units', 'downloadPkg',\n",
       "       'pubFormat', 'primaryKey', 'categoricalCodeName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datainpd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainpd.to_csv('/Users/athenaye/Desktop/alksd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablelist = [']\n",
    "sitelist = ['ARIK']\n",
    "\n",
    "#'YELL','WREF','WOOD','UNDE','UKFS','TREE','TOOL','TEAK','TALL',\n",
    "#'STER','STEI','SRER','SOAP','SJER',\n",
    "#'SERC','SCBI','RMNP',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sitelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbpdataset(slist, dp, variableint, desiredcol):\n",
    "    for x in range(len(slist)):\n",
    "        try:\n",
    "            stacked = neonUtilities.loadByProduct(dpID= dp,\n",
    "                                    site = slist[x],\n",
    "                                    package='basic',\n",
    "                                    check_size='FALSE',\n",
    "                                    nCores = 4)\n",
    "            with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "                    datainpd = ro.conversion.rpy2py(stacked[variableint])\n",
    "            datainpd['startDateTime'] = datainpd['startDateTime'].astype(str)\n",
    "            intermediatelist = datainpd[\"startDateTime\"].str.split(' ', n= -1, expand=True)\n",
    "            datainpd[\"startDateTime\"] = intermediatelist[0]\n",
    "            for y in range(len(desiredcol)):\n",
    "                df = pd.DataFrame(datainpd[['siteID', 'startDateTime', desiredcol[y]]])\n",
    "                df = df.groupby(['siteID','startDateTime'], as_index=False).mean()\n",
    "                df = pd.melt(df, id_vars=['siteID','startDateTime'], value_vars=[desiredcol[y]])\n",
    "                df.to_csv('/Users/athenaye/Desktop/steronward/' + str(slist[x]) + str(desiredcol[y]) + '.csv')\n",
    "        except:\n",
    "            print('Something went wrong with the site ' + str(slist[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding available files\n",
      "  |======================================================================| 100%\n",
      "\n",
      "Downloading files totaling approximately 3.734217254 GB\n",
      "Downloading 63 files\n",
      "  |======================================================================| 100%\n",
      "\n",
      "Unpacking zip files using 4 cores.\n",
      "  |                                                  | 0 % ~calculating   |++++                                              | 6 % ~09s           |+++++++                                           | 12% ~09s           |++++++++++                                        | 19% ~09s           |+++++++++++++                                     | 25% ~08s           |++++++++++++++++                                  | 31% ~07s           |+++++++++++++++++++                               | 38% ~07s           |++++++++++++++++++++++                            | 44% ~06s           |+++++++++++++++++++++++++                         | 50% ~05s           |+++++++++++++++++++++++++++++                     | 56% ~05s           |++++++++++++++++++++++++++++++++                  | 62% ~04s           |+++++++++++++++++++++++++++++++++++               | 69% ~03s           |++++++++++++++++++++++++++++++++++++++            | 75% ~03s           |+++++++++++++++++++++++++++++++++++++++++         | 81% ~02s           |++++++++++++++++++++++++++++++++++++++++++++      | 88% ~01s           |+++++++++++++++++++++++++++++++++++++++++++++++   | 94% ~01s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=11s  \n",
      "  |                                                  | 0 % ~calculating   |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=00s  \n",
      "Parallelizing stacking operation across 4 cores.\n",
      "Stacking table SCO2C_1_minute\n",
      "  |                                                  | 0 % ~calculating   |+                                                 | 1 % ~56s           |++                                                | 2 % ~60s           |++                                                | 3 % ~01m 02s       |+++                                               | 4 % ~01m 04s       |+++                                               | 5 % ~01m 06s       |++++                                              | 6 % ~01m 09s       |++++                                              | 7 % ~01m 08s       |+++++                                             | 8 % ~01m 09s       |+++++                                             | 9 % ~01m 09s       |++++++                                            | 11% ~01m 08s       |++++++                                            | 12% ~01m 08s       |+++++++                                           | 13% ~01m 08s       |+++++++                                           | 14% ~01m 08s       |++++++++                                          | 15% ~01m 06s       |++++++++                                          | 16% ~01m 06s       |+++++++++                                         | 17% ~01m 05s       |+++++++++                                         | 18% ~01m 05s       |++++++++++                                        | 19% ~01m 04s       |++++++++++                                        | 20% ~01m 03s       |+++++++++++                                       | 21% ~01m 03s       |++++++++++++                                      | 22% ~01m 03s       |++++++++++++                                      | 23% ~01m 02s       |+++++++++++++                                     | 24% ~01m 01s       |+++++++++++++                                     | 25% ~60s           |++++++++++++++                                    | 26% ~59s           |++++++++++++++                                    | 27% ~59s           |+++++++++++++++                                   | 28% ~58s           |+++++++++++++++                                   | 29% ~57s           |++++++++++++++++                                  | 31% ~56s           |++++++++++++++++                                  | 32% ~55s           |+++++++++++++++++                                 | 33% ~54s           |+++++++++++++++++                                 | 34% ~53s           |++++++++++++++++++                                | 35% ~52s           |++++++++++++++++++                                | 36% ~52s           |+++++++++++++++++++                               | 37% ~51s           |+++++++++++++++++++                               | 38% ~50s           |++++++++++++++++++++                              | 39% ~49s           |++++++++++++++++++++                              | 40% ~48s           |+++++++++++++++++++++                             | 41% ~47s           |++++++++++++++++++++++                            | 42% ~46s           |++++++++++++++++++++++                            | 43% ~46s           |+++++++++++++++++++++++                           | 44% ~45s           |+++++++++++++++++++++++                           | 45% ~44s           |++++++++++++++++++++++++                          | 46% ~43s           |++++++++++++++++++++++++                          | 47% ~42s           |+++++++++++++++++++++++++                         | 48% ~42s           |+++++++++++++++++++++++++                         | 49% ~41s           |++++++++++++++++++++++++++                        | 51% ~40s           |++++++++++++++++++++++++++                        | 52% ~39s           |+++++++++++++++++++++++++++                       | 53% ~39s           |+++++++++++++++++++++++++++                       | 54% ~38s           |++++++++++++++++++++++++++++                      | 55% ~37s           |++++++++++++++++++++++++++++                      | 56% ~36s           |+++++++++++++++++++++++++++++                     | 57% ~35s           |+++++++++++++++++++++++++++++                     | 58% ~35s           |++++++++++++++++++++++++++++++                    | 59% ~34s           |++++++++++++++++++++++++++++++                    | 60% ~33s           |+++++++++++++++++++++++++++++++                   | 61% ~32s           |++++++++++++++++++++++++++++++++                  | 62% ~31s           |++++++++++++++++++++++++++++++++                  | 63% ~30s           |+++++++++++++++++++++++++++++++++                 | 64% ~29s           |+++++++++++++++++++++++++++++++++                 | 65% ~28s           |++++++++++++++++++++++++++++++++++                | 66% ~27s           |++++++++++++++++++++++++++++++++++                | 67% ~27s           |+++++++++++++++++++++++++++++++++++               | 68% ~26s           |+++++++++++++++++++++++++++++++++++               | 69% ~25s           |++++++++++++++++++++++++++++++++++++              | 71% ~24s           |++++++++++++++++++++++++++++++++++++              | 72% ~23s           |+++++++++++++++++++++++++++++++++++++             | 73% ~22s           |+++++++++++++++++++++++++++++++++++++             | 74% ~22s           |++++++++++++++++++++++++++++++++++++++            | 75% ~21s           |++++++++++++++++++++++++++++++++++++++            | 76% ~20s           |+++++++++++++++++++++++++++++++++++++++           | 77% ~19s           |+++++++++++++++++++++++++++++++++++++++           | 78% ~18s           |++++++++++++++++++++++++++++++++++++++++          | 79% ~17s           |++++++++++++++++++++++++++++++++++++++++          | 80% ~16s           |+++++++++++++++++++++++++++++++++++++++++         | 81% ~16s           |++++++++++++++++++++++++++++++++++++++++++        | 82% ~15s           |++++++++++++++++++++++++++++++++++++++++++        | 83% ~14s           |+++++++++++++++++++++++++++++++++++++++++++       | 84% ~13s           |+++++++++++++++++++++++++++++++++++++++++++       | 85% ~12s           |++++++++++++++++++++++++++++++++++++++++++++      | 86% ~11s           |++++++++++++++++++++++++++++++++++++++++++++      | 87% ~10s           |+++++++++++++++++++++++++++++++++++++++++++++     | 88% ~10s           |+++++++++++++++++++++++++++++++++++++++++++++     | 89% ~09s           |++++++++++++++++++++++++++++++++++++++++++++++    | 91% ~08s           |++++++++++++++++++++++++++++++++++++++++++++++    | 92% ~07s           |+++++++++++++++++++++++++++++++++++++++++++++++   | 93% ~06s           |+++++++++++++++++++++++++++++++++++++++++++++++   | 94% ~05s           |++++++++++++++++++++++++++++++++++++++++++++++++  | 95% ~04s           |++++++++++++++++++++++++++++++++++++++++++++++++  | 96% ~03s           |+++++++++++++++++++++++++++++++++++++++++++++++++ | 97% ~03s           |+++++++++++++++++++++++++++++++++++++++++++++++++ | 98% ~02s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 99% ~01s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=01m 22s\n",
      "Stacking table SCO2C_30_minute                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |                                                  | 0 % ~calculating   |+                                                 | 1 % ~13s           |++                                                | 2 % ~12s           |++                                                | 3 % ~12s           |+++                                               | 4 % ~11s           |+++                                               | 5 % ~11s           |++++                                              | 6 % ~11s           |++++                                              | 7 % ~10s           |+++++                                             | 8 % ~10s           |+++++                                             | 9 % ~10s           |++++++                                            | 11% ~10s           |++++++                                            | 12% ~09s           |+++++++                                           | 13% ~09s           |+++++++                                           | 14% ~09s           |++++++++                                          | 15% ~09s           |++++++++                                          | 16% ~08s           |+++++++++                                         | 17% ~08s           |+++++++++                                         | 18% ~09s           |++++++++++                                        | 19% ~09s           |++++++++++                                        | 20% ~09s           |+++++++++++                                       | 21% ~09s           |++++++++++++                                      | 22% ~08s           |++++++++++++                                      | 23% ~08s           |+++++++++++++                                     | 24% ~08s           |+++++++++++++                                     | 25% ~08s           |++++++++++++++                                    | 26% ~07s           |++++++++++++++                                    | 27% ~07s           |+++++++++++++++                                   | 28% ~07s           |+++++++++++++++                                   | 29% ~07s           |++++++++++++++++                                  | 31% ~07s           |++++++++++++++++                                  | 32% ~07s           |+++++++++++++++++                                 | 33% ~07s           |+++++++++++++++++                                 | 34% ~06s           |++++++++++++++++++                                | 35% ~07s           |++++++++++++++++++                                | 36% ~07s           |+++++++++++++++++++                               | 37% ~06s           |+++++++++++++++++++                               | 38% ~06s           |++++++++++++++++++++                              | 39% ~06s           |++++++++++++++++++++                              | 40% ~06s           |+++++++++++++++++++++                             | 41% ~06s           |++++++++++++++++++++++                            | 42% ~06s           |++++++++++++++++++++++                            | 43% ~05s           |+++++++++++++++++++++++                           | 44% ~05s           |+++++++++++++++++++++++                           | 45% ~05s           |++++++++++++++++++++++++                          | 46% ~05s           |++++++++++++++++++++++++                          | 47% ~05s           |+++++++++++++++++++++++++                         | 48% ~05s           |+++++++++++++++++++++++++                         | 49% ~05s           |++++++++++++++++++++++++++                        | 51% ~05s           |++++++++++++++++++++++++++                        | 52% ~05s           |+++++++++++++++++++++++++++                       | 53% ~07s           |+++++++++++++++++++++++++++                       | 54% ~07s           |++++++++++++++++++++++++++++                      | 55% ~06s           |++++++++++++++++++++++++++++                      | 56% ~06s           |+++++++++++++++++++++++++++++                     | 57% ~06s           |+++++++++++++++++++++++++++++                     | 58% ~06s           |++++++++++++++++++++++++++++++                    | 59% ~06s           |++++++++++++++++++++++++++++++                    | 60% ~05s           |+++++++++++++++++++++++++++++++                   | 61% ~05s           |++++++++++++++++++++++++++++++++                  | 62% ~05s           |++++++++++++++++++++++++++++++++                  | 63% ~05s           |+++++++++++++++++++++++++++++++++                 | 64% ~05s           |+++++++++++++++++++++++++++++++++                 | 65% ~05s           |++++++++++++++++++++++++++++++++++                | 66% ~04s           |++++++++++++++++++++++++++++++++++                | 67% ~04s           |+++++++++++++++++++++++++++++++++++               | 68% ~04s           |+++++++++++++++++++++++++++++++++++               | 69% ~04s           |++++++++++++++++++++++++++++++++++++              | 71% ~04s           |++++++++++++++++++++++++++++++++++++              | 72% ~04s           |+++++++++++++++++++++++++++++++++++++             | 73% ~03s           |+++++++++++++++++++++++++++++++++++++             | 74% ~03s           |++++++++++++++++++++++++++++++++++++++            | 75% ~03s           |++++++++++++++++++++++++++++++++++++++            | 76% ~03s           |+++++++++++++++++++++++++++++++++++++++           | 77% ~03s           |+++++++++++++++++++++++++++++++++++++++           | 78% ~03s           |++++++++++++++++++++++++++++++++++++++++          | 79% ~03s           |++++++++++++++++++++++++++++++++++++++++          | 80% ~02s           |+++++++++++++++++++++++++++++++++++++++++         | 81% ~02s           |++++++++++++++++++++++++++++++++++++++++++        | 82% ~02s           |++++++++++++++++++++++++++++++++++++++++++        | 83% ~02s           |+++++++++++++++++++++++++++++++++++++++++++       | 84% ~02s           |+++++++++++++++++++++++++++++++++++++++++++       | 85% ~02s           |++++++++++++++++++++++++++++++++++++++++++++      | 86% ~02s           |++++++++++++++++++++++++++++++++++++++++++++      | 87% ~01s           |+++++++++++++++++++++++++++++++++++++++++++++     | 88% ~01s           |+++++++++++++++++++++++++++++++++++++++++++++     | 89% ~01s           |++++++++++++++++++++++++++++++++++++++++++++++    | 91% ~01s           |++++++++++++++++++++++++++++++++++++++++++++++    | 92% ~01s           |+++++++++++++++++++++++++++++++++++++++++++++++   | 93% ~01s           |+++++++++++++++++++++++++++++++++++++++++++++++   | 94% ~01s           |++++++++++++++++++++++++++++++++++++++++++++++++  | 95% ~01s           |++++++++++++++++++++++++++++++++++++++++++++++++  | 96% ~00s           |+++++++++++++++++++++++++++++++++++++++++++++++++ | 97% ~00s           |+++++++++++++++++++++++++++++++++++++++++++++++++ | 98% ~00s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 99% ~00s           |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=11s  \n",
      "Merged the most recent publication of sensor position files for each site and saved to /stackedFiles\n",
      "Copied the most recent publication of variable definition file to /stackedFiles\n",
      "Finished: Stacked 2 data tables and 3 metadata tables!\n",
      "Stacking took 2.761372 mins\n",
      "Finding available files\n",
      "  |======================================================================| 100%\n",
      "\n",
      "Downloading files totaling approximately 4.100573879 GB\n",
      "Downloading 70 files\n",
      "  |======================================================                |  77%"
     ]
    }
   ],
   "source": [
    "lbpdataset(sitelist,'DP1.00095.001', 3, variablelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check the chunk below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(variablelist)):\n",
    "    names=[]\n",
    "    for l in range(len(sitelist)):\n",
    "        name = '/Users/athenaye/Desktop/radiation/' + str(sitelist[l]) + str(variablelist[e]) + '.csv'\n",
    "        names += [name]\n",
    "    #try:\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in names])\n",
    "    combined_csv.to_csv('/Users/athenaye/Desktop/' + str(variablelist[e]) + '.csv', index=False )\n",
    "    #except:\n",
    "        #print('Something went wrong with the site ' + str(sitelist[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sitelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Time Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ziptolongform(stringfilepathofzip):\n",
    "    stringfilepathofstacked = stringfilepathofzip.replace('.zip', '/stackedFiles')\n",
    "    neonUtilities.stackByTable(filepath=stringfilepathofzip)\n",
    "    print(os.listdir(stringfilepathofstacked))\n",
    "    variable = input('What is the desired observation? ')\n",
    "    originaldf = pd.read_csv(stringfilepathofstacked + '/' + variable)\n",
    "    intermediatelist = originaldf[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    originaldf[\"startDateTime\"] = intermediatelist[0]\n",
    "    originaldf = originaldf.set_index(['siteID', 'startDateTime'])\n",
    "    print(originaldf.columns)\n",
    "    desiredcolumn = input('What is the desired column? ')\n",
    "    df = pd.read_csv(stringfilepathofstacked + '/' + variable)\n",
    "    intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    df[\"startDateTime\"] = intermediatelist[0]\n",
    "    df = df[['siteID', 'startDateTime', desiredcolumn]]\n",
    "    df = df.groupby(['siteID','startDateTime'], as_index=False).mean()\n",
    "    print(df)\n",
    "    df = pd.melt(df, id_vars=['siteID','startDateTime'], value_vars=[desiredcolumn])\n",
    "    del(variable)\n",
    "    del(originaldf)\n",
    "    del(intermediatelist)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nitratemean = ziptolongform('/Users/athenaye/Desktop/11/NEON_nitrate-surfacewater.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitratemean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitratemean.to_csv('/Users/athenaye/Desktop/nitratemean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd time around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master3 = pd.DataFrame()\n",
    "neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/12/0/NEON_par.zip')\n",
    "print(os.listdir('/Users/athenaye/Desktop/12/0/NEON_par/stackedFiles'))\n",
    "variable = input('What is the desired observation? ')\n",
    "originaldf = pd.read_csv('//Users/athenaye/Desktop/12/0/NEON_par/stackedFiles/' + variable)\n",
    "intermediatelist = originaldf[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "originaldf[\"startDateTime\"] = intermediatelist[0]\n",
    "originaldf = originaldf.set_index(['siteID', 'startDateTime'])\n",
    "print(originaldf.columns)\n",
    "desiredcolumn = input('What is the desired column? ')\n",
    "\n",
    "x = 1\n",
    "master3 = pd.DataFrame()\n",
    "for l in range(len(glob.glob('/Users/athenaye/Desktop/12/*/NEON_par.zip'))-1):\n",
    "    neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/12/' + str(x) + '/NEON_par.zip')\n",
    "    df = pd.read_csv('/Users/athenaye/Desktop/12/' + str(x) + '/NEON_par/stackedFiles/' + variable)\n",
    "    intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    df[\"startDateTime\"] = intermediatelist[0]\n",
    "    df = df[['siteID', 'startDateTime', desiredcolumn]]\n",
    "    df = df.groupby(['siteID','startDateTime'], as_index=False).mean()\n",
    "    df = pd.melt(df, id_vars=['siteID','startDateTime'], value_vars=[desiredcolumn])\n",
    "    master3 = pd.concat([master3, df], axis = 0)\n",
    "    print(x)\n",
    "    x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master2 = pd.DataFrame()\n",
    "neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/par-water-surface/0/NEON_par-water-surface.zip')\n",
    "print(os.listdir('/Users/athenaye/Desktop/par-water-surface/0/NEON_par-water-surface/stackedFiles'))\n",
    "variable = input('What is the desired observation? ')\n",
    "originaldf = pd.read_csv('/Users/athenaye/Desktop/par-water-surface/0/NEON_par-water-surface/stackedFiles/' + variable)\n",
    "intermediatelist = originaldf[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "originaldf[\"startDateTime\"] = intermediatelist[0]\n",
    "originaldf = originaldf.set_index(['siteID', 'startDateTime'])\n",
    "print(originaldf.columns)\n",
    "desiredcolumn = input('What is the desired column? ')\n",
    "\n",
    "x = 1\n",
    "master2 = pd.DataFrame()\n",
    "for l in range(len(glob.glob('/Users/athenaye/Desktop/par-water-surface/*/NEON_par-water-surface.zip'))-1):\n",
    "    neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/par-water-surface/' + str(x) + '/NEON_par-water-surface.zip')\n",
    "    print(os.listdir('/Users/athenaye/Desktop/par-water-surface/' + str(x) + '/NEON_par-water-surface/stackedFiles'))\n",
    "    df = pd.read_csv('/Users/athenaye/Desktop/par-water-surface/' + str(x) + '/NEON_par-water-surface/stackedFiles/' + variable)\n",
    "    intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    df[\"startDateTime\"] = intermediatelist[0]\n",
    "    df = df[['siteID', 'startDateTime', desiredcolumn]]\n",
    "    df = df.groupby(['siteID','startDateTime'], as_index=False).mean()\n",
    "    df = pd.melt(df, id_vars=['siteID','startDateTime'], value_vars=[desiredcolumn])\n",
    "    master2 = pd.concat([master2, df], axis = 0)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master2.to_csv('/Users/athenaye/Desktop/PARMean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master = pd.DataFrame()\n",
    "neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/Trial/0/NEON_elev-surfacewater.zip')\n",
    "print(os.listdir('/Users/athenaye/Desktop/Trial/0/NEON_elev-surfacewater/stackedFiles'))\n",
    "variable = input('What is the desired observation? ')\n",
    "originaldf = pd.read_csv('/Users/athenaye/Desktop/Trial/0/NEON_elev-surfacewater/stackedFiles/' + variable)\n",
    "intermediatelist = originaldf[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "originaldf[\"startDateTime\"] = intermediatelist[0]\n",
    "originaldf = originaldf.set_index(['siteID', 'startDateTime'])\n",
    "print(originaldf.columns)\n",
    "desiredcolumn = input('What is the desired column? ')\n",
    "\n",
    "x = 1\n",
    "master = pd.DataFrame()\n",
    "for l in range(len(glob.glob('/Users/athenaye/Desktop/Trial/*/NEON_elev-surfacewater.zip'))-1):\n",
    "    neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/Trial/' + str(x) + '/NEON_elev-surfacewater.zip')\n",
    "    print(os.listdir('/Users/athenaye/Desktop/Trial/' + str(x) + '/NEON_elev-surfacewater/stackedFiles'))\n",
    "    df = pd.read_csv('/Users/athenaye/Desktop/Trial/' + str(x) + '/NEON_elev-surfacewater/stackedFiles/' + variable)\n",
    "    intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    df[\"startDateTime\"] = intermediatelist[0]\n",
    "    df = df[['siteID', 'startDateTime', desiredcolumn]]\n",
    "    df = df.groupby(['siteID','startDateTime'], as_index=False).mean()\n",
    "    df = pd.melt(df, id_vars=['siteID','startDateTime'], value_vars=['surfacewaterElevMean'])\n",
    "    master = pd.concat([master, df], axis = 0)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "# Does multiindex save space?\n",
    "# Neon datasets, what would be good ones?\n",
    "# Get the coordinates for each site (Koppen Climate Classification??)\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv('/Users/athenaye/Desktop/ElevationSurfaceMean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.iloc[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10, 5))\n",
    "longform = sns.lineplot(y = 'value', x = 'startDateTime', hue = 'siteID', data = master.iloc[0:500])\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10, 5))\n",
    "longform = sns.lineplot(y = 'value', x = 'startDateTime', hue = 'siteID', data = master.iloc[0:1000])\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10, 5))\n",
    "longform = sns.lineplot(y = 'value', x = 'startDateTime', hue = 'siteID', data = master.iloc[0:25000])\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10, 5))\n",
    "longform = sns.lineplot(y = 'value', x = 'startDateTime', hue = 'siteID', data = master)\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/athenaye/Desktop/NEON_elev-surfacewater/stackedFiles/EOS_30_min.csv')\n",
    "intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "df[\"startDateTime\"] = intermediatelist[0]\n",
    "df = df[['siteID', 'startDateTime', desiredcolumn]]\n",
    "df = df.groupby(['siteID','startDateTime'], as_index=False).mean()\n",
    "df = pd.melt(df, id_vars=['siteID','startDateTime'], value_vars=['surfacewaterElevMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.get_level_values('startDateTime').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    neonUtilities.stackByTable(filepath='/Users/athenaye/Desktop/Trial/' + str(x) + '/NEON_elev-surfacewater.zip')\n",
    "    print(os.listdir('/Users/athenaye/Desktop/Trial/' + str(x) + '/NEON_elev-surfacewater/stackedFiles'))\n",
    "    df = pd.read_csv('/Users/athenaye/Desktop/Trial/' + str(x) + '/NEON_elev-surfacewater/stackedFiles/' + variable)\n",
    "    intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    df[\"startDateTime\"] = intermediatelist[0]\n",
    "    df = df.set_index(['siteID', 'startDateTime'])\n",
    "    df = df[[desiredcolumn]]\n",
    "    siteIDs = df.index.get_level_values('siteID').drop_duplicates()\n",
    "#     siteIDlist = []\n",
    "#     for q in range(len(siteIDs)):\n",
    "#         print(siteIDs[q])\n",
    "#         siteIDlist += [siteIDs[q]]\n",
    "    sample = df.xs(siteIDs[z]).groupby('startDateTime').mean()\n",
    "    sample.index = pd.to_datetime(sample.index)\n",
    "    sample = sample[[columnname]]\n",
    "    master = pd.concat([master, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myName = input('What is your name? ')\n",
    "print(\"hi\" + myName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allconcat = pd.DataFrame()\n",
    "for x in range(len(siteIDs)):\n",
    "    sample = thirty.xs(siteIDs[x]).groupby('startDateTime').mean()\n",
    "    sample.index = pd.to_datetime(sample.index)\n",
    "    emptylist = []\n",
    "    for y in range(len(sample)):\n",
    "        emptylist += [str(siteIDs[x])]\n",
    "    sample['site'] = emptylist\n",
    "    allconcat = pd.concat([allconcat,sample], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allconcat = pd.DataFrame()\n",
    "for z in range(len(siteIDs)):\n",
    "    sample = thirty.xs(siteIDs[z]).groupby('startDateTime').mean()\n",
    "    sample.index = pd.to_datetime(sample.index)\n",
    "    sample = sample[['PM15Median']]\n",
    "    for x in range(len(sample.columns)):\n",
    "        nonan = sample[sample.columns[x]]\n",
    "        nonan = nonan.interpolate('time', limit_direction='both')\n",
    "        a,b = plt.psd(nonan, Fs = 1, scale_by_freq = False, NFFT = 2**14 )\n",
    "        if x == 0:\n",
    "            acumulative = a\n",
    "            bcumulative = b\n",
    "        else:\n",
    "            acumulative = np.vstack([acumulative, a])\n",
    "            bcumulative = np.vstack([bcumulative, b])\n",
    "        amean = pd.DataFrame(acumulative, index = bcumulative)\n",
    "        base = sci.interpolate.interp1d(1/amean.index[1:],amean.iloc[1:,0], kind = 'nearest')\n",
    "        xvalues = np.linspace(1,13, num = 8193, endpoint = True)\n",
    "        xvalues = xvalues[::-1]\n",
    "        xvalues = 2**xvalues\n",
    "        interparray = base(xvalues)\n",
    "        amean = pd.DataFrame(interparray, index = bcumulative)\n",
    "        allconcat = pd.concat([allconcat, amean], axis = 1)\n",
    "allconcat.columns = siteIDlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.array(allconcat.index[1:])\n",
    "nfftexpnew = 14\n",
    "interpolated = pd.DataFrame()\n",
    "for x in range(len(allconcat.columns)):\n",
    "    base = sci.interpolate.interp1d(1/hi,allconcat.iloc[1:,x], kind = 'nearest')\n",
    "    xvalues = np.linspace(1,nfftexpnew-1, num = 8193, endpoint = True)\n",
    "    xvalues = xvalues[::-1]\n",
    "    xvalues = 2**xvalues\n",
    "    interparray = base(xvalues)\n",
    "    series = pd.Series(interparray, index = xvalues)\n",
    "    interpolated = pd.concat([interpolated, series], axis = 1)\n",
    "    interpolated.rename_axis('frequency')\n",
    "    interpolated.rename_axis('measurement', axis='columns')\n",
    "yvalues = np.array(range(0,8193)) #y-values\n",
    "xtickmarkloc = [2, 4, 8, 16, 32, 64, 128, 256, 365, 365*2, 365*4, 365*8, 365*16, 8192] #setting the xtickmark locations (numbers represent the period in days)\n",
    "xtickmarkloc = xtickmarkloc[0:nfftexpnew-1]\n",
    "x = xvalues #the x-values to interpolate along??\n",
    "y = yvalues #the y-values to interpolate along??\n",
    "f = sci.interpolate.interp1d(x, y) #interpolating \n",
    "xnew = xtickmarkloc #the desired x-values\n",
    "ynew = f(xnew) #list of values\n",
    "interpolated.columns = allconcat.columns\n",
    "s = sns.heatmap(np.log(interpolated.T), cbar_kws={'label': 'Log of Power Spectral Density'}) #creating the heatmap and labeling the color bar\n",
    "s.set_title('Power Spectral Density') #setting the heatmap title\n",
    "s.set_xlabel('Period (days)') #setting the heatmap x-axis label\n",
    "s.set_ylabel('Measurement') #setting the heatmap x-axis label\n",
    "newlabel = ['2d', '4d','8d','16d','32d','64d','128d','256d','1yr', '2yr', '4yr', '8yr', '16yr', '8192d'] #setting the x-axis labels\n",
    "newlabel = newlabel[0:nfftexpnew-1]\n",
    "plt.xticks(ynew, newlabel) #plotting the x-ticks and the newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neontohm(df, columnname, nfft):\n",
    "    intermediatelist = df[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "    df[\"startDateTime\"] = intermediatelist[0]\n",
    "    df = df.set_index(['siteID', 'startDateTime'])\n",
    "    df = df[[columnname]]\n",
    "    siteIDs = df.index.get_level_values('siteID').drop_duplicates()\n",
    "    siteIDlist = []\n",
    "    for q in range(len(siteIDs)):\n",
    "        print(siteIDs[q])\n",
    "        siteIDlist += [siteIDs[q]]\n",
    "    allconcat = pd.DataFrame()\n",
    "#     for x in range(len(siteIDs)):\n",
    "#         sample = df.xs(siteIDs[x]).groupby('startDateTime').mean()\n",
    "#         sample.index = pd.to_datetime(sample.index)\n",
    "#         emptylist = []\n",
    "#         for y in range(len(sample)):\n",
    "#             emptylist += [str(siteIDs[x])]\n",
    "#         sample['site'] = emptylist\n",
    "#         allconcat = pd.concat([allconcat, sample], axis = 0)\n",
    "    allconcat = pd.DataFrame()\n",
    "    for z in range(len(siteIDs)):\n",
    "        sample = df.xs(siteIDs[z]).groupby('startDateTime').mean()\n",
    "        sample.index = pd.to_datetime(sample.index)\n",
    "        sample = sample[[columnname]]\n",
    "        print(sample)\n",
    "        for x in range(len(sample.columns)):\n",
    "            nonan = sample[sample.columns[x]]\n",
    "            nonan = nonan.interpolate('time', limit_direction='both')\n",
    "            a,b = plt.psd(nonan, Fs = 1, scale_by_freq = False, NFFT = 2**14 )\n",
    "            if x == 0:\n",
    "                acumulative = a\n",
    "                bcumulative = b\n",
    "            else:\n",
    "                acumulative = np.vstack([acumulative, a])\n",
    "                bcumulative = np.vstack([bcumulative, b])\n",
    "            amean = pd.DataFrame(acumulative, index = bcumulative)\n",
    "            base = sci.interpolate.interp1d(1/amean.index[1:],amean.iloc[1:,0], kind = 'nearest')\n",
    "            xvalues = np.linspace(1,13, num = 8193, endpoint = True)\n",
    "            xvalues = xvalues[::-1]\n",
    "            xvalues = 2**xvalues\n",
    "            interparray = base(xvalues)\n",
    "            amean = pd.DataFrame(interparray, index = bcumulative)\n",
    "            allconcat = pd.concat([allconcat, amean], axis = 1)\n",
    "    allconcat.columns = siteIDlist\n",
    "    hi = np.array(allconcat.index[1:])\n",
    "    nfftexpnew = 8\n",
    "    interpolated = pd.DataFrame()\n",
    "    for x in range(len(allconcat.columns)):\n",
    "        base = sci.interpolate.interp1d(1/hi,allconcat.iloc[1:,x], kind = 'nearest')\n",
    "        xvalues = np.linspace(1,nfftexpnew-1, num = 8193, endpoint = True)\n",
    "        xvalues = xvalues[::-1]\n",
    "        xvalues = 2**xvalues\n",
    "        interparray = base(xvalues)\n",
    "        series = pd.Series(interparray, index = xvalues)\n",
    "        interpolated = pd.concat([interpolated, series], axis = 1)\n",
    "        interpolated.rename_axis('frequency')\n",
    "        interpolated.rename_axis('measurement', axis='columns')\n",
    "    yvalues = np.array(range(0,8193)) #y-values\n",
    "    xtickmarkloc = [2, 4, 8, 16, 32, 64, 128, 256, 365, 365*2, 365*4, 365*8, 365*16, 8192] #setting the xtickmark locations (numbers represent the period in days)\n",
    "    xtickmarkloc = xtickmarkloc[0:nfftexpnew-1]\n",
    "    x = xvalues #the x-values to interpolate along??\n",
    "    y = yvalues #the y-values to interpolate along??\n",
    "    f = sci.interpolate.interp1d(x, y) #interpolating \n",
    "    xnew = xtickmarkloc #the desired x-values\n",
    "    ynew = f(xnew) #list of values\n",
    "    interpolated.columns = allconcat.columns\n",
    "    s = sns.heatmap(np.log(interpolated.T), cbar_kws={'label': 'Log of Power Spectral Density'}) #creating the heatmap and labeling the color bar\n",
    "    s.set_title('Power Spectral Density') #setting the heatmap title\n",
    "    s.set_xlabel('Period (days)') #setting the heatmap x-axis label\n",
    "    s.set_ylabel('Barometric Pressure') #setting the heatmap x-axis label\n",
    "    newlabel = ['2d', '4d','8d','16d','32d','64d','128d','256d','1yr', '2yr', '4yr', '8yr', '16yr', '8192d'] #setting the x-axis labels\n",
    "    newlabel = newlabel[0:nfftexpnew-1]\n",
    "    plt.xticks(ynew, newlabel) #plotting the x-ticks and the newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neontohm(nitrate,'surfWaterNitrateMean', 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break every 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrate = pd.read_csv('/Users/athenaye/Downloads/NEON_nitrate-surfacewater/stackedFiles/NSW_15_minute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leco = nitrate.loc[nitrate['siteID'] == 'LEWI']\n",
    "indexofnan = leco[leco['surfWaterNitrateMean'].isna()].index\n",
    "indexofnan = indexofnan.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "# Creating dataset\n",
    "a = []\n",
    "for x in range(406):\n",
    "    a.append(1)\n",
    "for x in range(304):\n",
    "    a.append(2)\n",
    "for x in range(84):\n",
    "    a.append(3)\n",
    "for x in range(291):\n",
    "    a.append(4)\n",
    "for x in range(340):\n",
    "    a.append(5)\n",
    " \n",
    "# Creating histogram\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a, bins = [0.5,1.5,2.5,3.5,4.5,5.5])\n",
    " \n",
    "# Show plot\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Length of Segment')\n",
    "plt.title('Length of Each Segment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listofmaxminnan)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrate = pd.read_csv('/Users/athenaye/Downloads/NEON_nitrate-surfacewater/stackedFiles/NSW_15_minute.csv')\n",
    "\n",
    "intermediatelist = nitrate[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "nitrate[\"startDateTime\"] = intermediatelist[0]\n",
    "nitrate = nitrate.set_index(['siteID', 'startDateTime'])\n",
    "nitrate = nitrate[['surfWaterNitrateMean']]\n",
    "siteIDs = nitrate.index.get_level_values('siteID').drop_duplicates()\n",
    "siteIDlist = []\n",
    "for q in range(len(siteIDs)):\n",
    "    siteIDlist += [siteIDs[q]]\n",
    "allconcat = pd.DataFrame()\n",
    "for z in range(len(siteIDs)):\n",
    "    sample = nitrate.xs(siteIDs[z]).groupby('startDateTime').mean()\n",
    "    sample.index = pd.to_datetime(sample.index)\n",
    "    sample = sample[['surfWaterNitrateMean']]\n",
    "    plt.plot(sample)\n",
    "    for x in range(len(sample.columns)):\n",
    "        nonan = sample[sample.columns[x]]\n",
    "        nonan = nonan.interpolate('time', limit_direction='both')\n",
    "        a,b = plt.psd(nonan, Fs = 1, scale_by_freq = False, NFFT = 2**14 )\n",
    "        if x == 0:\n",
    "            acumulative = a\n",
    "            bcumulative = b\n",
    "        else:\n",
    "            acumulative = np.vstack([acumulative, a])\n",
    "            bcumulative = np.vstack([bcumulative, b])\n",
    "        print(bcumulative)\n",
    "        amean = pd.DataFrame(acumulative, index = bcumulative)\n",
    "#         base = sci.interpolate.interp1d(1/amean.index[1:],amean.iloc[1:,0], kind = 'nearest')\n",
    "#         xvalues = np.linspace(1,13, num = 8193, endpoint = True)\n",
    "#         xvalues = xvalues[::-1]\n",
    "#         xvalues = 2**xvalues\n",
    "#         interparray = base(xvalues)\n",
    "#         amean = pd.DataFrame(interparray, index = bcumulative)\n",
    "#         allconcat = pd.concat([allconcat, amean], axis = 1)\n",
    "# allconcat.columns = siteIDlist\n",
    "# hi = np.array(allconcat.index[1:])\n",
    "# nfftexpnew = 8\n",
    "# interpolated = pd.DataFrame()\n",
    "# for x in range(len(allconcat.columns)):\n",
    "#     base = sci.interpolate.interp1d(1/hi,allconcat.iloc[1:,x], kind = 'nearest')\n",
    "#     xvalues = np.linspace(1,nfftexpnew-1, num = 8193, endpoint = True)\n",
    "#     xvalues = xvalues[::-1]\n",
    "#     xvalues = 2**xvalues\n",
    "#     interparray = base(xvalues)\n",
    "#     series = pd.Series(interparray, index = xvalues)\n",
    "#     interpolated = pd.concat([interpolated, series], axis = 1)\n",
    "#     interpolated.rename_axis('frequency')\n",
    "#     interpolated.rename_axis('measurement', axis='columns')\n",
    "# yvalues = np.array(range(0,8193)) #y-values\n",
    "# xtickmarkloc = [2, 4, 8, 16, 32, 64, 128, 256, 365, 365*2, 365*4, 365*8, 365*16, 8192] #setting the xtickmark locations (numbers represent the period in days)\n",
    "# xtickmarkloc = xtickmarkloc[0:nfftexpnew-1]\n",
    "# x = xvalues #the x-values to interpolate along??\n",
    "# y = yvalues #the y-values to interpolate along??\n",
    "# f = sci.interpolate.interp1d(x, y) #interpolating \n",
    "# xnew = xtickmarkloc #the desired x-values\n",
    "# ynew = f(xnew) #list of values\n",
    "# interpolated.columns = allconcat.columns\n",
    "# s = sns.heatmap(np.log(interpolated.T), cbar_kws={'label': 'Log of Power Spectral Density'}) #creating the heatmap and labeling the color bar\n",
    "# s.set_title('Power Spectral Density') #setting the heatmap title\n",
    "# s.set_xlabel('Period (days)') #setting the heatmap x-axis label\n",
    "# s.set_ylabel('Measurement') #setting the heatmap x-axis label\n",
    "# newlabel = ['2d', '4d','8d','16d','32d','64d','128d','256d','1yr', '2yr', '4yr', '8yr', '16yr', '8192d'] #setting the x-axis labels\n",
    "# newlabel = newlabel[0:nfftexpnew-1]\n",
    "# plt.xticks(ynew, newlabel) #plotting the x-ticks and the newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediatelist = thirty[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "thirty[\"startDateTime\"] = intermediatelist[0]\n",
    "thirty = thirty.groupby(siteIDs[x]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in glob.glob('/Users/athenaye/Downloads/NEON_pressure-air/NEON.D10.ARIK.DP1.00004.001.20**-**.basic.20210123T023002Z.RELEASE-2021'):\n",
    "    endoff = re.sub('.basic.20210123T023002Z.RELEASE-2021', '', name)\n",
    "    alloff = re.sub('NEON.D10.ARIK.DP1.00004.001.', '', endoff)\n",
    "    os.rename(name, alloff)\n",
    "\n",
    "for name in glob.glob('/Users/athenaye/Downloads/NEON_pressure-air/200.000.001.BP_1min.*'):\n",
    "    alloff = re.sub('200.000.001.BP_1min.', '', name)\n",
    "    os.rename(name, alloff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "october2018 = pd.read_csv('./PollenandBird/2018-10', index_col = 'startDateTime')\n",
    "october2018 = october2018.drop('endDateTime', axis=1)\n",
    "october2018.index = october2018.index.str.split('T', n= -1, expand=True)\n",
    "october2018 = october2018.droplevel(1, axis=0)\n",
    "october2018 = october2018.groupby(october2018.index).mean()\n",
    "october2018 = october2018['staPresMean']\n",
    "october2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(october2018['staPresMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoffiles = ['2018-10', '2018-11','2018-12','2019-01','2019-02','2019-03','2019-04','2019-05','2019-06','2019-07','2019-08','2019-09','2019-10','2019-11','2019-12','2020-01','2020-02','2020-03','2020-04','2020-05','2020-06']\n",
    "listoffiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpressure = pd.DataFrame()\n",
    "for x in listoffiles:\n",
    "    nameoffile = './PollenandBird/' + str(x)\n",
    "    onebyone = pd.read_csv(nameoffile, index_col = 'startDateTime')\n",
    "    onebyone = onebyone.drop('endDateTime', axis=1)\n",
    "    onebyone.index = onebyone.index.str.split('T', n= -1, expand=True)\n",
    "    onebyone = onebyone.droplevel(1, axis=0)\n",
    "    onebyone = onebyone.groupby(onebyone.index).mean()\n",
    "    onebyone = onebyone['staPresMean']\n",
    "    airpressure = pd.concat([airpressure, onebyone], axis = 0)\n",
    "airpressure.to_csv('./PollenandBird/airpressure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpressure.index = range(len(airpressure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(airpressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrate = pd.read_csv('/Users/athenaye/Downloads/NEON_nitrate-surfacewater/stackedFiles/NSW_15_minute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediatelist = nitrate[\"startDateTime\"].str.split('T', n= -1, expand=True)\n",
    "nitrate[\"startDateTime\"] = intermediatelist[0]\n",
    "nitrate = nitrate.set_index(['siteID', 'startDateTime'])\n",
    "nitrate = nitrate[['surfWaterNitrateMean']]\n",
    "siteIDs = nitrate.index.get_level_values('siteID').drop_duplicates()\n",
    "siteIDlist = []\n",
    "for q in range(len(siteIDs)):\n",
    "    print(siteIDs[q])\n",
    "    siteIDlist += [siteIDs[q]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allconcat = pd.DataFrame()\n",
    "for z in range(len(siteIDs)):\n",
    "    sample = nitrate.xs(siteIDs[z]).groupby('startDateTime').mean()\n",
    "    sample.index = pd.to_datetime(sample.index)\n",
    "    sample = sample[['surfWaterNitrateMean']]\n",
    "    for x in range(len(sample.columns)):\n",
    "        nonan = sample[sample.columns[x]]\n",
    "        nonan = nonan.interpolate('time', limit_direction='both')\n",
    "        a,b = plt.psd(nonan, Fs = 1, scale_by_freq = False, NFFT = 2**14 )\n",
    "        if x == 0:\n",
    "            acumulative = a\n",
    "            bcumulative = b\n",
    "        else:\n",
    "            acumulative = np.vstack([acumulative, a])\n",
    "            bcumulative = np.vstack([bcumulative, b])\n",
    "        amean = pd.DataFrame(acumulative, index = bcumulative)\n",
    "        base = sci.interpolate.interp1d(1/amean.index[1:],amean.iloc[1:,0], kind = 'nearest')\n",
    "        xvalues = np.linspace(1,13, num = 8193, endpoint = True)\n",
    "        xvalues = xvalues[::-1]\n",
    "        xvalues = 2**xvalues\n",
    "        interparray = base(xvalues)\n",
    "        amean = pd.DataFrame(interparray, index = bcumulative)\n",
    "        allconcat = pd.concat([allconcat, amean], axis = 1)\n",
    "allconcat.columns = siteIDlist\n",
    "print(allconcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.array(allconcat.index[1:])\n",
    "nfftexpnew = 8\n",
    "interpolated = pd.DataFrame()\n",
    "for x in range(len(allconcat.columns)):\n",
    "    base = sci.interpolate.interp1d(1/hi,allconcat.iloc[1:,x], kind = 'nearest')\n",
    "    xvalues = np.linspace(1,nfftexpnew-1, num = 8193, endpoint = True)\n",
    "    xvalues = xvalues[::-1]\n",
    "    xvalues = 2**xvalues\n",
    "    interparray = base(xvalues)\n",
    "    series = pd.Series(interparray, index = xvalues)\n",
    "    interpolated = pd.concat([interpolated, series], axis = 1)\n",
    "    interpolated.rename_axis('frequency')\n",
    "    interpolated.rename_axis('measurement', axis='columns')\n",
    "yvalues = np.array(range(0,8193)) #y-values\n",
    "xtickmarkloc = [2, 4, 8, 16, 32, 64, 128, 256, 365, 365*2, 365*4, 365*8, 365*16, 8192] #setting the xtickmark locations (numbers represent the period in days)\n",
    "xtickmarkloc = xtickmarkloc[0:nfftexpnew-1]\n",
    "x = xvalues #the x-values to interpolate along??\n",
    "y = yvalues #the y-values to interpolate along??\n",
    "f = sci.interpolate.interp1d(x, y) #interpolating \n",
    "xnew = xtickmarkloc #the desired x-values\n",
    "ynew = f(xnew) #list of values\n",
    "interpolated.columns = allconcat.columns\n",
    "s = sns.heatmap(np.log(interpolated.T), cbar_kws={'label': 'Log of Power Spectral Density'}) #creating the heatmap and labeling the color bar\n",
    "s.set_title('Power Spectral Density') #setting the heatmap title\n",
    "s.set_xlabel('Period (days)') #setting the heatmap x-axis label\n",
    "s.set_ylabel('Measurement') #setting the heatmap x-axis label\n",
    "newlabel = ['2d', '4d','8d','16d','32d','64d','128d','256d','1yr', '2yr', '4yr', '8yr', '16yr', '8192d'] #setting the x-axis labels\n",
    "newlabel = newlabel[0:nfftexpnew-1]\n",
    "plt.xticks(ynew, newlabel) #plotting the x-ticks and the newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
